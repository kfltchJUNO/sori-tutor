import { GoogleGenerativeAI } from "@google/generative-ai";
import { NextResponse } from "next/server";

// 1. ğŸ”¥ [í•µì‹¬ ìˆ˜ì •] Vercelì— ë“±ë¡í•œ 'GEMINI_API_KEY'ë¥¼ ê°€ì¥ ë¨¼ì € ì°¾ë„ë¡ ìˆ˜ì •
// í˜¹ì‹œ ëª¨ë¥¼ ìƒí™©ì„ ëŒ€ë¹„í•´ ë‹¤ë¥¸ ì´ë¦„ë“¤ë„ ë‹¤ ì°¾ì•„ë´…ë‹ˆë‹¤. (í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ OK)
const apiKey = process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY || process.env.NEXT_PUBLIC_GEMINI_API_KEY;

// 2. ğŸ”¥ [ìš”ì²­í•˜ì‹  ëª¨ë¸ ì „ëµ] 2.5 Flash -> Lite ìˆœì„œ
const modelCandidates = [
  "gemini-2.5-flash",       // 1ìˆœìœ„: ë©”ì¸ ëª¨ë¸ (ì„±ëŠ¥)
  "gemini-2.5-flash-lite",  // 2ìˆœìœ„: ë°±ì—… ëª¨ë¸ (ê°€ì„±ë¹„)
  "gemini-1.5-flash"        // 3ìˆœìœ„: ìµœí›„ì˜ ì•ˆì „ì¥ì¹˜ (êµ¬ê¸€ í‘œì¤€ ëª¨ë¸)
];

export async function POST(req: Request) {
  try {
    const formData = await req.formData();
    const audioFile = formData.get("audio") as Blob;
    const targetText = formData.get("targetText") as string;
    const context = formData.get("context") as string;

    // ë””ë²„ê¹… ë¡œê·¸: í‚¤ê°€ ì˜ ë¡œë“œëëŠ”ì§€ í™•ì¸ (ë³´ì•ˆìƒ ê°’ì€ ìˆ¨ê¹€)
    console.log("Analyze ìš”ì²­ ì‹œì‘");
    console.log(`- API Key ìƒíƒœ: ${apiKey ? "âœ… ë¡œë“œë¨" : "âŒ ì—†ìŒ (GEMINI_API_KEY í™•ì¸ í•„ìš”)"}`);

    // í‚¤ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°˜í™˜
    if (!apiKey) {
      return NextResponse.json({ 
        error: "API Key Missing", 
        details: "Vercel í™˜ê²½ë³€ìˆ˜ì— 'GEMINI_API_KEY'ê°€ ì—†ìŠµë‹ˆë‹¤." 
      }, { status: 500 });
    }

    if (!audioFile) {
      return NextResponse.json({ error: "No audio provided" }, { status: 400 });
    }

    // Google AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    const genAI = new GoogleGenerativeAI(apiKey);
    
    // ì˜¤ë””ì˜¤ ë²„í¼ ë³€í™˜
    const buffer = Buffer.from(await audioFile.arrayBuffer());
    const base64Audio = buffer.toString("base64");

    let finalResult = null;
    let errorLog = "";

    // ğŸ”¥ ëª¨ë¸ ìˆœì°¨ ì‹œë„ (Fail-over System)
    for (const modelName of modelCandidates) {
      try {
        console.log(`Trying model: ${modelName}...`);
        const model = genAI.getGenerativeModel({ model: modelName });

        const prompt = `
          Role: Strict Korean Pronunciation Coach.
          Target: "${targetText}"
          Context: "${context}"
          
          STEP 1: Check content (Most Important).
          - Listen carefully. Did the user say "${targetText}"?
          - If the user said different words or missed key parts:
            -> Set SCORE to 10.
            -> Set FEEDBACK to "ë‹¤ë¥¸ ë¬¸ì¥ì„ ë§ì”€í•˜ì‹  ê²ƒ ê°™ì•„ìš”. ë¬¸ì¥ì„ ë‹¤ì‹œ í™•ì¸í•˜ê³  ì½ì–´ì£¼ì„¸ìš”!".
            -> Output JSON immediately.

          STEP 2: Analyze Pronunciation (Only if content matches).
          - Evaluate pitch, speed, and intonation naturally.
          - Score scale: 0 to 100.
          - Feedback: Keep it polite (í•´ìš”-che), specific to the error.

          Output JSON ONLY: { "score": number, "feedback": "string" }
        `;

        const result = await model.generateContent([
          prompt,
          { inlineData: { mimeType: "audio/webm", data: base64Audio } }
        ]);

        const responseText = result.response.text();
        
        // JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì œê±°)
        const cleanJson = responseText.replace(/```json|```/g, "").trim();
        finalResult = JSON.parse(cleanJson);
        
        console.log(`âœ… Success with ${modelName}`);
        break; // ì„±ê³µí•˜ë©´ ë°˜ë³µë¬¸ ì¢…ë£Œ

      } catch (e: any) {
        console.warn(`âš ï¸ Model ${modelName} failed:`, e.message);
        errorLog += `[${modelName}: ${e.message}] `;
        // ì‹¤íŒ¨í•˜ë©´ ë‹¤ìŒ ëª¨ë¸ë¡œ ë„˜ì–´ê° (continue)
      }
    }

    // ëª¨ë“  ëª¨ë¸ì´ ì‹¤íŒ¨í–ˆì„ ê²½ìš°
    if (!finalResult) {
      console.error("All models failed:", errorLog);
      throw new Error(`ëª¨ë“  AI ëª¨ë¸ ì‘ë‹µ ì‹¤íŒ¨: ${errorLog}`);
    }

    return NextResponse.json(finalResult);

  } catch (error: any) {
    console.error("Critical Error:", error);
    return NextResponse.json({ 
      error: "Analysis failed", 
      details: error.message 
    }, { status: 500 });
  }
}