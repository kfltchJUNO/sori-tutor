import { NextResponse } from "next/server";
import { GoogleGenerativeAI } from "@google/generative-ai";
import { TextToSpeechClient } from "@google-cloud/text-to-speech";

// ğŸ”¥ [í•µì‹¬] íŠ¹ìˆ˜ë¬¸ì/ë§ˆí¬ë‹¤ìš´ ì œê±° í•¨ìˆ˜ (ë³„í‘œë³„í‘œ ì†Œë¦¬ ë°©ì§€)
function cleanTextForTTS(text: string) {
  return text
    .replace(/\*\*/g, "")   // êµµê²Œ(**) ì œê±°
    .replace(/\*/g, "")     // ê¸°ìš¸ì„(*) ì œê±°
    .replace(/__/g, "")     // ë°‘ì¤„(__) ì œê±°
    .replace(/`/g, "")      // ì½”ë“œ ë¸”ë¡(`) ì œê±°
    .replace(/-/g, " ")     // í•˜ì´í”ˆ(-) ì œê±° (í•„ìš” ì‹œ)
    .trim();
}

export async function POST(req: Request) {
  try {
    const formData = await req.formData();
    const action = formData.get("action") as string;
    
    // í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    const apiKey = process.env.GOOGLE_API_KEY || process.env.NEXT_PUBLIC_GEMINI_API_KEY;
    const googleCreds = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON; // Vercelìš© JSON í™˜ê²½ë³€ìˆ˜

    if (!apiKey) return NextResponse.json({ error: "API Key Error" }, { status: 500 });

    const genAI = new GoogleGenerativeAI(apiKey);
    
    // êµ¬ê¸€ TTS í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
    // (ë¡œì»¬ì—ì„œëŠ” keyFile ê²½ë¡œ, ë°°í¬ í™˜ê²½ì—ì„œëŠ” credentials JSON íŒŒì‹±)
    const ttsClient = new TextToSpeechClient(
        googleCreds ? { credentials: JSON.parse(googleCreds) } : {}
    );

    // ==========================================
    // 1. [TTS ë‹¨ìˆœ ë³€í™˜] (tts_simple)
    // ==========================================
    if (action === "tts_simple") {
      const text = formData.get("text") as string;
      const voiceName = formData.get("voiceName") as string || "ko-KR-Chirp3-HD-Zephyr";

      if (!text) return NextResponse.json({ error: "No text" });

      // ğŸ”¥ TTS ë³€í™˜ ì „ í…ìŠ¤íŠ¸ ì„¸íƒ
      const cleanText = cleanTextForTTS(text);

      const request = {
        input: { text: cleanText },
        voice: { languageCode: "ko-KR", name: voiceName },
        audioConfig: { audioEncoding: "MP3" as const, speakingRate: 1.0 },
      };

      const [response] = await ttsClient.synthesizeSpeech(request);
      const audioContent = response.audioContent?.toString("base64");

      return NextResponse.json({ audioContent });
    }

    // ==========================================
    // 2. [ììœ  íšŒí™”] (chat)
    // ==========================================
    if (action === "chat") {
      const historyStr = formData.get("history") as string;
      const personaId = formData.get("persona") as string;
      const sharedMemory = formData.get("sharedMemory") as string || "";
      const audioFile = formData.get("audio") as Blob;

      const history = JSON.parse(historyStr || "[]");
      const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" }); // ìµœì‹  ëª¨ë¸ ì‚¬ìš© ê¶Œì¥

      let userText = "";

      // 2-1. ì‚¬ìš©ì ì˜¤ë””ì˜¤ STT (Speech-to-Text)
      // (ì˜¤ë””ì˜¤ê°€ ìˆìœ¼ë©´ Gemini ë©€í‹°ëª¨ë‹¬ë¡œ í…ìŠ¤íŠ¸ ë³€í™˜, ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ì…ë ¥ ê°€ì •)
      if (audioFile) {
        const arrayBuffer = await audioFile.arrayBuffer();
        const base64Audio = Buffer.from(arrayBuffer).toString("base64");
        
        // STT ì „ìš© í”„ë¡¬í”„íŠ¸
        const sttResult = await model.generateContent([
          "Transcribe exactly what the user said in Korean.",
          { inlineData: { mimeType: "audio/webm", data: base64Audio } }
        ]);
        userText = sttResult.response.text();
      }

      // 2-2. AI ì‘ë‹µ ìƒì„±
      // í˜ë¥´ì†Œë‚˜ ì„¤ì • (ê°„ëµ ì˜ˆì‹œ)
      const personaSystemPrompts: any = {
        su: "ë„ˆëŠ” í™œë°œí•œ 20ëŒ€ ëŒ€í•™ìƒ 'ìˆ˜ê²½'ì´ì•¼. ë°˜ë§ë¡œ ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•´. ì´ëª¨í‹°ì½˜ì„ ì ì ˆíˆ ì‚¬ìš©í•´.",
        min: "ë„ˆëŠ” ê°ì„±ì ì¸ 30ëŒ€ ì¹´í˜ ì‚¬ì¥ 'ë¯¼ì² 'ì´ì•¼. ì¡´ëŒ“ë§ë¡œ ë¶€ë“œëŸ½ê²Œ ëŒ€í™”í•´.",
        jin: "ë„ˆëŠ” ê¹ê¹í•œ ëŒ€ê¸°ì—… ë¶€ì¥ 'ì§„ì„±'ì´ì•¼. ë…¼ë¦¬ì ì´ê³  ì§ì„¤ì ìœ¼ë¡œ ë§í•´.",
        // ... (ë‚˜ë¨¸ì§€ í˜ë¥´ì†Œë‚˜ë„ í•„ìš” ì‹œ ì¶”ê°€)
        default: "ë„ˆëŠ” ì¹œì ˆí•œ í•œêµ­ì–´ íŠœí„°ì•¼."
      };
      
      const systemPrompt = `
        ${personaSystemPrompts[personaId] || personaSystemPrompts.default}
        
        [ê¸°ì–µ ì •ë³´]
        ${sharedMemory}

        [ëŒ€í™” ê·œì¹™]
        1. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ 2~3ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ í•´ì¤˜.
        2. **ì ˆëŒ€ë¡œ ë§ˆí¬ë‹¤ìš´ ë³¼ë“œì²´(**)ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆ.** (ì¤‘ìš”)
        3. ìƒëŒ€ë°©ì˜ ë§ì„ ì˜ ë“£ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ì¤˜.
      `;

      const chat = model.startChat({
        history: history.map((h: any) => ({
          role: h.role,
          parts: [{ text: h.text }]
        })),
        generationConfig: { maxOutputTokens: 300 },
      });

      // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì£¼ì… (ê¼¼ìˆ˜: ì²« í„´ì— instructionìœ¼ë¡œ ë„£ê±°ë‚˜ systemInstruction ì˜µì…˜ ì‚¬ìš© ê°€ëŠ¥)
      // ì—¬ê¸°ì„œëŠ” ë©”ì‹œì§€ì— í¬í•¨í•´ì„œ ë³´ëƒ„
      const finalPrompt = `${systemPrompt}\n\nì‚¬ìš©ì ë©”ì‹œì§€: ${userText}`;
      const result = await chat.sendMessage(finalPrompt);
      const aiText = result.response.text();

      // 2-3. AI ì‘ë‹µ TTS ë³€í™˜
      // ğŸ”¥ ì—¬ê¸°ì„œë„ í•œ ë²ˆ ë” í…ìŠ¤íŠ¸ ì„¸íƒ (AIê°€ í˜¹ì‹œë¼ë„ **ë¥¼ ì¼ì„ê¹Œë´)
      const cleanAiText = cleanTextForTTS(aiText);

      // í˜ë¥´ì†Œë‚˜ë³„ ëª©ì†Œë¦¬ ë§¤í•‘
      const voices: any = {
        su: "ko-KR-Chirp3-HD-Zephyr",
        min: "ko-KR-Chirp3-HD-Rasalgethi",
        jin: "ko-KR-Chirp3-HD-Algenib",
        seol: "ko-KR-Chirp3-HD-Despina",
        do: "ko-KR-Chirp3-HD-Achird",
        ju: "ko-KR-Chirp3-HD-Sadachbia",
        hye: "ko-KR-Chirp3-HD-Aoede",
        woo: "ko-KR-Chirp3-HD-Charon",
        hyun: "ko-KR-Chirp3-HD-Zubenelgenubi",
        sun: "ko-KR-Chirp3-HD-Vindemiatrix",
      };
      const voiceName = voices[personaId] || "ko-KR-Chirp3-HD-Zephyr";

      const ttsRequest = {
        input: { text: cleanAiText }, // ì„¸íƒëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
        voice: { languageCode: "ko-KR", name: voiceName },
        audioConfig: { audioEncoding: "MP3" as const, speakingRate: 1.0 },
      };

      const [ttsResponse] = await ttsClient.synthesizeSpeech(ttsRequest);
      const audioContent = ttsResponse.audioContent?.toString("base64");

      return NextResponse.json({
        userText,
        aiText, // í™”ë©´ì—ëŠ” ì›ë˜ í…ìŠ¤íŠ¸(ì´ëª¨í‹°ì½˜ ë“± í¬í•¨) ë³´ì—¬ì¤Œ
        audioContent, // ì†Œë¦¬ëŠ” ì„¸íƒëœ í…ìŠ¤íŠ¸ë¡œ ë‚˜ì˜´
      });
    }

    // ==========================================
    // 3. [í”¼ë“œë°± ìƒì„±] (feedback)
    // ==========================================
    if (action === "feedback") {
      const historyStr = formData.get("history") as string;
      const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });
      
      const prompt = `
        ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•´ì„œ í•œêµ­ì–´ í•™ìŠµìë¥¼ ìœ„í•œ í”¼ë“œë°±ì„ JSONìœ¼ë¡œ ì¤˜.
        ëŒ€í™” ë‚´ìš©: ${historyStr}
        
        í˜•ì‹:
        {
          "pronunciation": "ë°œìŒ/ì–´íœ˜ í”¼ë“œë°±",
          "intonation": "ì–µì–‘/ê°ì • í”¼ë“œë°±",
          "general": "ì´í‰ ë° ì¡°ì–¸"
        }
      `;
      
      const result = await model.generateContent(prompt);
      const text = result.response.text().replace(/```json|```/g, "").trim();
      return NextResponse.json(JSON.parse(text));
    }

    // ==========================================
    // 4. [ë²ˆì—­] (translate)
    // ==========================================
    if (action === "translate") {
      const text = formData.get("text") as string;
      const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });
      
      const result = await model.generateContent(`Translate this Korean text to English naturally:\n\n${text}`);
      return NextResponse.json({ translatedText: result.response.text() });
    }

    // ==========================================
    // 5. [ê¸°ì–µ ë™ê¸°í™”] (memory_sync)
    // ==========================================
    if (action === "memory_sync") {
       const currentMemory = formData.get("currentMemory") as string;
       const newDialog = formData.get("newDialog") as string;
       const mode = formData.get("mode") as string;
       
       const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });
       let prompt = "";
       
       if (mode === 'compress') {
           prompt = `Update the user summary based on the new dialog. Keep it concise.\nCurrent: ${currentMemory}\nNew Dialog: ${newDialog}`;
       } else {
           prompt = `Extract key facts about the user from this dialog to append to memory. If none, say "ì •ë³´ ì—†ìŒ".\nDialog: ${newDialog}`;
       }
       
       const result = await model.generateContent(prompt);
       return NextResponse.json({ summary: result.response.text() });
    }

    return NextResponse.json({ error: "Invalid action" }, { status: 400 });

  } catch (error: any) {
    console.error("API Error:", error);
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}