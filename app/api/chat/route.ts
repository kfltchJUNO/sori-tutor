import { NextResponse } from "next/server";
import { GoogleGenerativeAI } from "@google/generative-ai";

export async function POST(req: Request) {
  try {
    const formData = await req.formData();
    const action = formData.get("action") as string; 
    
    // API í‚¤ í™•ì¸
    const apiKey = process.env.GOOGLE_TTS_API_KEY || process.env.GOOGLE_API_KEY || process.env.NEXT_PUBLIC_GEMINI_API_KEY;
    if (!apiKey) {
        console.error("API Key Missing");
        return NextResponse.json({ error: "Server Configuration Error" }, { status: 500 });
    }
    
    const genAI = new GoogleGenerativeAI(apiKey);
    // ê°€ì¥ ë¹ ë¥´ê³  ì•ˆì •ì ì¸ ëª¨ë¸ ì‚¬ìš©
    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });

    // --- [ê¸°ëŠ¥ 1] ëŒ€í™” ì§„í–‰ ---
    if (action === "chat") {
      const audioFile = formData.get("audio") as Blob;
      const historyStr = formData.get("history") as string;
      const persona = formData.get("persona") as string;
      const history = JSON.parse(historyStr || "[]");

      if (!audioFile) return NextResponse.json({ error: "Audio missing" }, { status: 400 });

      // 1. ì˜¤ë””ì˜¤ -> í…ìŠ¤íŠ¸ ë³€í™˜ ë° ì‘ë‹µ ìƒì„± (Gemini)
      const arrayBuffer = await audioFile.arrayBuffer();
      const base64Audio = Buffer.from(arrayBuffer).toString("base64");

      // í˜ë¥´ì†Œë‚˜ ì„¤ì •
      const personaConfig = persona === 'min' 
        ? { name: 'ë¯¼ì² ', style: 'í™œê¸°ì°¨ê³  ì—ë„ˆì§€ ë„˜ì¹˜ëŠ”' }
        : { name: 'ìˆ˜ê²½', style: 'ì°¨ë¶„í•˜ê³  ìƒëƒ¥í•œ' };

      const systemPrompt = `
        ë‹¹ì‹ ì€ í•œêµ­ì–´ í•™ìŠµìì˜ ì¹œêµ¬ '${personaConfig.name}'ì…ë‹ˆë‹¤. (${personaConfig.style} ì„±ê²©)
        
        [ìˆ˜í–‰ ì—­í• ]
        1. **STT**: ì‚¬ìš©ìì˜ ì˜¤ë””ì˜¤ë¥¼ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¡œ ì ìœ¼ì„¸ìš”. ì˜¤íƒ€ë‚˜ ë°œìŒ ì‹¤ìˆ˜ëŠ” **ë¬¸ë§¥ì— ë§ê²Œ í‘œì¤€ì–´ë¡œ ë³´ì •**í•˜ì„¸ìš”.
        2. **ëŒ€í™”**: ë³´ì •ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”. (ë°˜ë§ ì‚¬ìš©)
        
        [ì¢…ë£Œ ê·œì¹™]
        - ìƒëŒ€ë°©ì´ 'ì‘', 'ì•„ë‹ˆ' ë“± ë‹¨ë‹µì„ 2íšŒ ì´ìƒ í•˜ê±°ë‚˜ ì˜ë¯¸ ì—†ëŠ” ì†Œë¦¬ë¥¼ ë‚´ë©´ ëŒ€í™”ë¥¼ ì •ì¤‘íˆ ì¢…ë£Œí•˜ì„¸ìš”(ended: true).

        [ì¶œë ¥ í¬ë§· (JSON Only)]
        {
          "userTranscript": "ë³´ì •ëœ ì‚¬ìš©ì ë°œí™”",
          "aiResponse": "AI ë‹µë³€",
          "ended": true/false
        }
      `;

      let chatContext = history.map((msg: any) => `${msg.role === 'user' ? 'ì‚¬ìš©ì' : personaConfig.name}: ${msg.text}`).join("\n");
      
      let aiData;
      try {
        const result = await model.generateContent([
            systemPrompt,
            `[ì´ì „ ëŒ€í™”]\n${chatContext}\n\n[í˜„ì¬ ì‚¬ìš©ì ì˜¤ë””ì˜¤]`,
            { inlineData: { mimeType: "audio/webm", data: base64Audio } }
        ]);
        
        const responseText = result.response.text().replace(/```json|```/g, "").trim();
        aiData = JSON.parse(responseText);
      } catch (e) {
        console.error("Gemini Error:", e);
        return NextResponse.json({ error: "AI ì¸ì‹ ì‹¤íŒ¨" }, { status: 500 });
      }

      // 2. TTS ìƒì„± (Google Cloud TTS)
      // ğŸ”¥ [ìˆ˜ì •ë¨] ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ Google Cloud TTS ì„±ìš° ì´ë¦„ ì‚¬ìš©
      // ìˆ˜ê²½(ì—¬) -> ko-KR-Neural2-A (ë˜ëŠ” Wavenet-A)
      // ë¯¼ì² (ë‚¨) -> ko-KR-Neural2-C (ë˜ëŠ” Wavenet-C)
      let audioContent = null;
      const targetVoice = persona === 'min' ? "ko-KR-Neural2-C" : "ko-KR-Neural2-A";
      
      try {
          const ttsRes = await fetch(`https://texttospeech.googleapis.com/v1/text:synthesize?key=${apiKey}`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
                input: { text: aiData.aiResponse },
                voice: { languageCode: "ko-KR", name: targetVoice },
                audioConfig: { audioEncoding: "MP3", speakingRate: 1.0 } // ì†ë„ ì¡°ì ˆ ê°€ëŠ¥
            })
          });
          
          if (!ttsRes.ok) {
             const errData = await ttsRes.json();
             console.error("TTS API Error:", errData);
             // TTS ì‹¤íŒ¨í•´ë„ í…ìŠ¤íŠ¸ëŠ” ë°˜í™˜í•´ì•¼ í•¨ (ì¡°ìš©íˆ ë„˜ì–´ê°)
          } else {
             const ttsData = await ttsRes.json();
             audioContent = ttsData.audioContent;
          }
      } catch (e) { console.error("TTS Net Error", e); }

      return NextResponse.json({ 
          userText: aiData.userTranscript || "(ì†Œë¦¬ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤)", 
          aiText: aiData.aiResponse,       
          ended: aiData.ended,
          audioContent: audioContent       
      });
    }

    // --- [ê¸°ëŠ¥ 2] í”¼ë“œë°± ---
    if (action === "feedback") {
        const historyStr = formData.get("history") as string;
        const history = JSON.parse(historyStr || "[]");
        const feedbackPrompt = `
            ë‹¹ì‹ ì€ í•œêµ­ì–´ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ëŒ€í™”ë¥¼ ë¶„ì„í•´ JSONìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.
            [ëŒ€í™”] ${history.map((m:any)=>m.text).join("\n")}
            [ì¶œë ¥] {"pronunciation":"ë°œìŒ í‰ê°€...", "intonation":"ì–µì–‘/ê°ì • í‰ê°€...", "general":"ì´í‰..."}
        `;
        const result = await model.generateContent(feedbackPrompt);
        const text = result.response.text().replace(/```json|```/g, "").trim();
        return NextResponse.json(JSON.parse(text));
    }

    return NextResponse.json({ error: "Invalid action" }, { status: 400 });

  } catch (error: any) {
    console.error("Final Error:", error);
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}